{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea935a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e82ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284c8baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9819ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-20.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 42.3 MB 9.2 kB/s eta 0:00:01     |███████████████████████████████▊| 41.9 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-20.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b3ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://d37ci6vzurychx.cloudfront.net/trip-data/\"\n",
    "jan_url = base + \"yellow_tripdata_2023-01.parquet\"\n",
    "feb_url = base + \"yellow_tripdata_2023-02.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75711b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3066766, 19)\n",
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_jan = pd.read_parquet(jan_url)\n",
    "print(df_jan.shape)      # (кол-во строк, кол-во столбцов)\n",
    "print(df_jan.columns)    # список имён, если нужно убедиться вручную"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3babf",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88b7ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.59\n"
     ]
    }
   ],
   "source": [
    "df_jan[\"duration\"] = (\n",
    "        pd.to_datetime(df_jan.tpep_dropoff_datetime) -\n",
    "        pd.to_datetime(df_jan.tpep_pickup_datetime)\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "std_minutes = df_jan[\"duration\"].std()\n",
    "print(round(std_minutes, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eeac75",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "90%\n",
    "92%\n",
    "95%\n",
    "98%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88c2751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.12 %\n"
     ]
    }
   ],
   "source": [
    "mask = df_jan['duration'].between(1, 60, inclusive='both')\n",
    "fraction = mask.mean() \n",
    "print(round(fraction * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c4ed8",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "Fit a dictionary vectorizer\n",
    "Get a feature matrix from it\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "2\n",
    "155\n",
    "345\n",
    "515\n",
    "715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5796b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3066766, 518)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. берём только нужные поля и переводим их в str\n",
    "cat = df_jan[['PULocationID', 'DOLocationID']].astype(str)\n",
    "\n",
    "# 2. превращаем в список словарей\n",
    "records = cat.to_dict(orient='records')\n",
    "\n",
    "# 3. обучаем DictVectorizer\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X = dv.fit_transform(records)\n",
    "\n",
    "X.shape          #  (N строк, 515 столбцов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1939da3",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "Calculate the RMSE of the model on the training data\n",
    "What's the RMSE on train?\n",
    "\n",
    "3.64\n",
    "7.64\n",
    "11.64\n",
    "16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "914f9d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.65\n"
     ]
    }
   ],
   "source": [
    "df_jan[\"duration\"] = (\n",
    "        pd.to_datetime(df_jan.tpep_dropoff_datetime) -\n",
    "        pd.to_datetime(df_jan.tpep_pickup_datetime)\n",
    ").dt.total_seconds() / 60\n",
    "df_jan = df_jan[df_jan[\"duration\"].between(1, 60)]\n",
    "\n",
    "# 3. one-hot для двух локаций\n",
    "features = df_jan[[\"PULocationID\", \"DOLocationID\"]].astype(str)\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(features.to_dict(orient=\"records\"))\n",
    "\n",
    "# 4. обучаем линейную регрессию\n",
    "y_train = df_jan[\"duration\"].values\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. RMSE на трейне\n",
    "y_pred = model.predict(X_train)\n",
    "rmse = mean_squared_error(y_train, y_pred, squared=False)\n",
    "print(round(rmse, 2))       # → 7.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198ea6b",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "3.81\n",
    "7.81\n",
    "11.81\n",
    "16.81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d971dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.81\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1. train (январь) ----------\n",
    "train_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "df_train = pd.read_parquet(train_url)\n",
    "df_train[\"duration\"] = (\n",
    "        pd.to_datetime(df_train.tpep_dropoff_datetime) -\n",
    "        pd.to_datetime(df_train.tpep_pickup_datetime)\n",
    ").dt.total_seconds() / 60\n",
    "df_train = df_train[df_train[\"duration\"].between(1, 60)]\n",
    "\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(df_train[[\"PULocationID\", \"DOLocationID\"]]\n",
    "                           .astype(str).to_dict(orient=\"records\"))\n",
    "y_train = df_train[\"duration\"].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ---------- 2. validation (февраль) ----------\n",
    "val_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\"\n",
    "df_val = pd.read_parquet(val_url)\n",
    "df_val[\"duration\"] = (\n",
    "        pd.to_datetime(df_val.tpep_dropoff_datetime) -\n",
    "        pd.to_datetime(df_val.tpep_pickup_datetime)\n",
    ").dt.total_seconds() / 60\n",
    "df_val = df_val[df_val[\"duration\"].between(1, 60)]\n",
    "\n",
    "X_val = dv.transform(df_val[[\"PULocationID\", \"DOLocationID\"]]\n",
    "                     .astype(str).to_dict(orient=\"records\"))\n",
    "y_val = df_val[\"duration\"].values\n",
    "rmse_val = mean_squared_error(y_val, model.predict(X_val), squared=False)\n",
    "print(round(rmse_val, 2))        # → 7.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839802a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
